# Detailed Application Workflow - Scenario-Based Documentation

This document describes what happens in the application through detailed scenarios showing user actions, frontend behavior, and backend operations.

---

## 1. Login & Authentication

### Scenario Table: User Login Flow

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| Navigate to login page | Login form with "Sign In" and "Sign Up" options | N/A | Login page displayed |
| Click "Sign Up" | Registration form appears | N/A | New client onboarding form shown |
| Enter client details and submit | Form submission, loading spinner | POST `/api/auth/register` â†’ Creates client record â†’ Generates credentials â†’ Assigns role â†’ Creates dashboard access | New client created, credentials returned |
| Receive credentials | Success message with username/password | Client record saved to database | User can now login |
| Click "Sign In" | Login form with username/password fields | N/A | Login form displayed |
| Enter credentials (e.g., admin/admin) | Loading spinner during authentication | POST `/api/auth/login` â†’ Validates credentials â†’ Checks role â†’ Generates JWT token â†’ Returns user data | Authentication token generated |
| Successful login as Admin | Redirect to Admin Dashboard | Session created, token stored | Admin Dashboard loads |
| Successful login as Client | Redirect to Client Dashboard | Session created, token stored | Client Dashboard loads |
| Successful login as Lab | Redirect to Lab Dashboard | Session created, token stored | Lab Dashboard loads |

---

## 2. Admin Dashboard - Live Operations

### Scenario Table: Viewing Real-Time Metrics

| User Action | What User Sees (Frontend) | What Happens (Backend) | Data Displayed | Update Frequency |
|-------------|---------------------------|------------------------|----------------|------------------|
| Navigate to Live Operations | Loading state, then 4 metric cards displayed | GET `/api/admin/system/overview` â†’ Queries all managed instances â†’ Counts active instances â†’ Checks risk notices (24h) â†’ Calculates cost savings â†’ Counts ML switches | Active Instances: 245<br>Risk Detected: 12<br>Cost Savings: $18,456<br>Optimizations: 1,234 | Auto-refresh every 30s |
| View Active Instances card | Card shows real-time count with trend indicator | Query: `SELECT COUNT(*) FROM instances WHERE status='running'` | Live count of platform-wide managed instances | Real-time |
| View Risk Detected card | Card shows count of notices in last 24h | Query: `SELECT COUNT(*) FROM notifications WHERE type IN ('rebalance', 'termination') AND created_at > NOW() - INTERVAL 24 HOUR` | Count of rebalance/termination notices | Real-time |
| View Cost Savings card | Card shows dollar amount and percentage | Calculation: `SUM(client_ondemand_cost) - SUM(current_spot_cost)` across all clients | Platform-wide savings | Real-time |
| View Optimizations card | Card shows total switch count | Query: `SELECT COUNT(*) FROM switch_history WHERE status='completed'` | Total ML-driven switches performed | Real-time |

### Scenario Table: Decision Pipeline Funnel

| User Action | What User Sees (Frontend) | What Happens (Backend) | Visualization |
|-------------|---------------------------|------------------------|---------------|
| View Pipeline Funnel section | Animated funnel chart with 4 stages | GET `/api/pipeline/funnel` â†’ Queries ML pipeline metrics â†’ Gets pool counts at each stage | Stage 1: 500 pools scanned<br>Stage 2: 400 after static filters<br>Stage 3: 350 after ML prediction<br>Stage 4: 5 final selections |
| Hover over funnel stage | Tooltip shows stage details (name, count, description) | N/A (client-side) | Interactive tooltip with stage info |
| Wait 30 seconds | Funnel updates with new data | Same API called again â†’ New counts fetched | Updated funnel with latest pipeline data |

### Scenario Table: Pipeline Status Monitoring

| User Action | What User Sees (Frontend) | What Happens (Backend) | Component Status |
|-------------|---------------------------|------------------------|------------------|
| View Pipeline Status panel | List of 4 backend components with status badges | GET `/api/admin/system/overview` â†’ Checks each component health | Scraper: HEALTHY<br>Risk Engine: HEALTHY<br>Cost Optimizer: DEGRADED<br>K8s Controller: HEALTHY |
| See DEGRADED component | Yellow badge with warning icon | Component is communicating but not processing data | Shows warning state |
| View System Load bar | Progress bar showing 45% load | Calculation: `(current_requests / max_capacity) * 100` | Visual load indicator |

---

## 3. Admin Dashboard - Node Fleet

### Scenario Table: Viewing Client List

| User Action | What User Sees (Frontend) | What Happens (Backend) | Data Displayed |
|-------------|---------------------------|------------------------|----------------|
| Navigate to Node Fleet | Loading, then client cards grid | GET `/api/admin/clients` â†’ Queries all clients â†’ For each client: counts instances, calculates savings | Grid of client cards |
| View client card | Card shows client name, node count, savings amount | Per client: `SELECT COUNT(*) FROM instances WHERE client_id = ?`<br>`SELECT SUM(savings) FROM cost_tracking WHERE client_id = ?` | Client: "Acme Corp"<br>Nodes: 45<br>Savings: $3,245 |
| Click on client card | Navigation animation, then client dashboard loads | Session updated with client context â†’ GET `/api/client/{id}/dashboard` â†’ Fetches client-specific data | Redirects to Client Dashboard view |
| View Total Monthly Saving | Displays aggregated savings | SUM of all client savings from cards | Same as Live Operations Cost Savings |
| View Total Active Nodes | Displays total instance count | SUM of all client node counts | Same as Live Operations Active Instances |

---

## 4. Admin Dashboard - System Monitor

### Scenario Table: Component Health Monitoring

| User Action | What User Sees (Frontend) | What Happens (Backend) | Component Details |
|-------------|---------------------------|------------------------|-------------------|
| Navigate to System Monitor | 3 status count cards + 10 component cards | GET `/api/admin/system/overview` â†’ Runs health checks on all 10 components â†’ Calculates uptime, latency â†’ Fetches recent logs | HEALTHY: 7<br>DEGRADED: 2<br>CRITICAL: 1 |
| View Database component card | Card shows: Status badge, Uptime (12d 5h), Avg Latency (45ms), Last 5 logs | Health check: Ping database â†’ Check connection pool â†’ Query response time<br>GET `/api/admin/components/database/logs?limit=5` | Shows real-time component metrics |
| View Redis Cache component | Status: DEGRADED, Uptime (2d 3h), Latency (120ms), Last 5 logs | Health check: Redis PING command â†’ Check memory usage â†’ Check connection count | Warning indicators shown |
| View ML Inference component | Status: CRITICAL, Uptime (0h 15m), Latency (N/A), Last 10 logs (due to state change) | Health check: Check ML service endpoint â†’ Verify model loaded â†’ Test prediction latency<br>Logs expanded to 10 due to state change | Shows critical error state and extended logs |
| Click Auto Refresh toggle | Toggle switches ON, "Auto-refreshing" indicator appears | Client-side timer starts â†’ Every 30s: Fetches component status + new logs | Background polling enabled |
| Click Manual Refresh button | Button shows spinner, all cards refresh | Immediately triggers: GET `/api/admin/system/overview` â†’ GET `/api/admin/components/{id}/logs` for all components | All component data updated |

### Scenario Table: Component State Change

| Event | What User Sees (Frontend) | What Happens (Backend) | Logging Behavior |
|-------|---------------------------|------------------------|------------------|
| Price Scraper goes from HEALTHY to CRITICAL | Status badge changes from green to red, log count increases from 5 to 10 | Health check fails â†’ Component marks state change timestamp â†’ Fetches last 10 logs since state change | Extended logging: Shows 10 activities from state change point to current |
| Component recovers to HEALTHY | Badge changes back to green, log count returns to 5 | Health check succeeds â†’ State change recorded â†’ Normal logging resumes | Returns to showing last 5 logs |

---

## 5. Admin Dashboard - Global Controls

### Scenario Table: Model Management

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| View model dropdown | Dropdown shows all available models: Uploaded, Lab-graduated, Current | GET `/api/admin/ml-models/sessions` â†’ Queries model registry â†’ Returns all models with status | List: Model-v1.0 (Stable), Model-v1.1 (Graduated), Model-v2.0-beta (Uploaded) |
| View current model info | Display shows: "Model-v1.0", Activated: "2025-12-01", Uptime: "18 days" | Queries active model record â†’ Calculates uptime from activation timestamp | Current production model details |
| Drag model file to upload area | File preview appears, "Upload" button enabled | N/A (client-side file handling) | File ready for upload |
| Click Upload button | Progress bar animates, success message appears | POST `/api/admin/ml-models/upload` (multipart/form-data) â†’ Saves file to storage â†’ Validates model format â†’ Creates model record â†’ Status: "Uploaded" | New model stored in system |
| Select new model from dropdown | Model selection highlighted | N/A (client-side state) | New model selected but not active |
| Click "Apply Changes" | Confirmation modal appears: "Apply Model-v1.1 to production?" | N/A (waiting for confirmation) | Confirmation required |
| Confirm model application | Loading indicator, then success: "Model activated, flushing cache..." | POST `/api/admin/ml-models/activate` â†’ Stops old model â†’ Loads new model â†’ Warms up cache â†’ Updates active model record â†’ Restarts inference service | New model live in production |

### Scenario Table: Manual Override - Force On-Demand

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| Click "Manual Override" button | Warning modal appears: "Switch ALL nodes to on-demand?" | N/A (client-side confirmation) | Confirmation dialog shown |
| Confirm override | Modal shows progress bar starting at 0% | POST `/api/admin/override/spot-market` â†’ Queries all spot instances â†’ For each instance: Initiates switch to on-demand â†’ Waits for confirmation â†’ Updates progress | Platform-wide switch initiated |
| Watch progress bar | Bar increases: 10% â†’ 50% â†’ 100%, shows "145/145 nodes switched" | For each instance:<br>1. Send switch command to cloud provider<br>2. Wait for instance to stabilize on on-demand<br>3. Update instance record: `status='on-demand'`<br>4. Increment progress counter<br>WebSocket pushes progress updates to frontend | All instances on on-demand |
| See "Done" at 100% | Success message: "All nodes on on-demand. Safe for maintenance." | All instances verified and updated | Maintenance mode enabled |

### Scenario Table: Re-compute Risk Scores

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| Click "Re-compute Risk Scores" | Button shows spinner, progress notification appears | POST `/api/admin/recompute-risk` â†’ Triggers ML job â†’ Fetches latest spot termination data â†’ For each instance: Recalculates risk score â†’ Updates risk database â†’ Triggers rebalancing if thresholds exceeded | Risk scores updated platform-wide |
| Job completes | Success notification: "Risk scores updated for 245 instances" | Job completion logged â†’ Notifications sent for high-risk instances | Updated risk assessments ready |

---

## 6. Admin Dashboard - Client Management

### Scenario Table: Managing Clients

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| Navigate to Client Management | Table/list of all clients with columns: Name, Role, Status, Last Login | GET `/api/v1/admin/users` â†’ Queries user table â†’ Returns all clients with metadata | Client list displayed |
| Click "Add Client" button | Modal opens with form: Name, Email, Role (dropdown) | N/A (client-side modal) | Create client form shown |
| Fill form and submit | Loading spinner, then success: "Client created successfully" | POST `/api/v1/admin/users` â†’ Creates user record â†’ Generates random password â†’ Hashes password â†’ Assigns role â†’ Creates dashboard access â†’ Returns credentials | New client created:<br>Username: client@example.com<br>Password: [generated]<br>Role: Client |
| View credentials display | Modal shows: "Credentials created: username/password" (copyable) | N/A | User can copy credentials |
| Click action button on client row | Edit modal opens showing: Role dropdown, Status toggle (Active/Blocked) | N/A (client-side) | Edit form displayed |
| Change role from Client to Lab | Dropdown updates to "Lab" | N/A (client-side state) | Role selection changed |
| Toggle status to "Blocked" | Toggle switches to blocked state, red indicator | N/A (client-side state) | Status changed locally |
| Click "Apply Changes" | Confirmation: "Update client access?", then loading | PUT `/api/v1/admin/users/{id}` â†’ Updates user record: `role='lab', status='blocked'` â†’ Invalidates existing sessions â†’ Logs change | Client updated:<br>Role: Lab<br>Status: Blocked<br>Cannot login until unblocked |
| Click delete button | Confirmation modal: "Permanently delete this client?" | N/A (warning shown) | Confirmation required |
| Confirm deletion | Loading, client removed from list | DELETE `/api/v1/admin/users/{id}` â†’ Soft delete: `deleted_at=NOW()` â†’ Archives associated data â†’ Cleans up sessions | Client removed (soft delete) |

---

## 7. Admin Dashboard - Admin Profile

### Scenario Table: Profile Management

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| Navigate to Admin Profile | Form with fields: Current Username, New Username, Current Password, New Password | N/A | Profile form displayed |
| Enter new username | Field updates with new value | N/A (client-side) | Username entered |
| Enter current and new password | Password fields masked with dots | N/A (client-side) | Passwords entered |
| Click "Save Changes" | Loading spinner on button | PUT `/api/admin/profile` â†’ Validates current password â†’ Checks username availability â†’ Hashes new password â†’ Updates admin record â†’ Invalidates old sessions â†’ Issues new JWT | Profile updated, re-authentication required |
| Auto-logout after update | Redirect to login with message: "Profile updated. Please login with new credentials." | Session invalidated | User must login again |

---

## 8. Client Dashboard - Fleet Topology

### Scenario Table: Cycle View Mode

| User Action | What User Sees (Frontend) | What Happens (Backend) | Visualization |
|-------------|---------------------------|------------------------|---------------|
| Navigate to Dashboard (Cycle View active) | Animated rotating banner showing clusters | GET `/api/client/{id}/topology` â†’ Fetches client clusters â†’ Returns cluster names, node counts, health status | Banner rotates showing:<br>Cluster 1 â†’ Engine â†’ Nodes (45)<br>[Animation cycles to next]<br>Cluster 2 â†’ Engine â†’ Nodes (32) |
| View cluster component | Visual card showing cluster name with icon | N/A (from fetched data) | "Production-Cluster-A" displayed |
| View engine component | Middle component showing "Atharva.AI Engine" with logo | N/A | Engine visualization |
| View nodes component | Shows node count + health status: Heart icon + "Healthy & Optimised" | Health calculated from: All nodes operational AND no pending switches | "45 nodes â¤ï¸ Healthy & Optimised" |
| Cycle rotates automatically | Smooth transition animation to next cluster | N/A (client-side animation) | Cycles through all 3 clusters every 5 seconds |

### Scenario Table: Live View Mode

| User Action | What User Sees (Frontend) | What Happens (Backend) | Visualization |
|-------------|---------------------------|------------------------|---------------|
| Switch to Live View mode | Real-time switching visualization appears | WebSocket connection established â†’ Subscribes to client's live events | Live view active |
| ML suggests a switch | Animation shows: Current Node â†’ Switching Arrow â†’ Target Node | Backend ML engine: Identifies better pool â†’ Creates switch recommendation â†’ Publishes to WebSocket: `{type: 'switch_suggested', from: 'i-123', to: 'pool-456'}` | Shows switching animation with both node details |
| Switch executes | Animated progress: Preparing â†’ Switching â†’ Verifying â†’ Complete | Backend executor:<br>1. Launches new instance in target pool<br>2. Waits for health checks<br>3. Transfers workload<br>4. Terminates old instance<br>WebSocket pushes progress updates | Progress animation shown |
| Switch completes | "Done" checkmark animation, then fades out | WebSocket: `{type: 'switch_completed', instance: 'i-123', new_pool: 'pool-456'}` â†’ Updates instance record | Success indicator shown |
| Multiple switches on same cluster | Panel shows 2 nodes side-by-side with switching animations | Multiple switch events received simultaneously | Scaled view showing parallel switches |
| Switches on multiple clusters | Section expands vertically, showing both clusters | WebSocket events from different clusters | Multi-cluster view with separate animations |
| Force rebalance triggered (from admin) | All nodes show "Reverting to On-Demand" animation | Admin triggers override â†’ WebSocket broadcasts to all clients â†’ Shows mass migration animation | Platform-wide fallback visualized |

---

## 9. Client Dashboard - Cost Savings Overview

### Scenario Table: Total Savings Mode

| User Action | What User Sees (Frontend) | What Happens (Backend) | Chart Display |
|-------------|---------------------------|------------------------|---------------|
| View Cost Savings (Total mode) | Line chart showing on-demand vs spot cost over time | GET `/api/client/{id}/savings-overview?mode=total` â†’ Queries cost tracking â†’ Calculates daily: on-demand baseline vs actual spend â†’ Returns time series data | Blue line: On-demand cost ($12,000/mo)<br>Green line: Actual spot cost ($4,500/mo)<br>Shaded area: Savings ($7,500/mo) |
| Hover over chart point | Tooltip shows: Date, On-demand: $400, Spot: $150, Saved: $250 | N/A (client-side) | Interactive tooltip |
| View savings percentage | Badge shows "62% savings" | Calculation: `((on_demand - actual) / on_demand) * 100` | Percentage badge displayed |

### Scenario Table: Cluster-wise Savings Mode

| User Action | What User Sees (Frontend) | What Happens (Backend) | Chart Display |
|-------------|---------------------------|------------------------|---------------|
| Switch to Cluster-wise mode | Cluster selector dropdown appears above chart | N/A (mode change) | Dropdown shows: All Clusters, Prod-Cluster-A, Prod-Cluster-B, Dev-Cluster |
| Select "Prod-Cluster-A" | Chart updates showing cluster-specific savings | GET `/api/client/{id}/savings-overview?mode=cluster&cluster_id=A` â†’ Filters cost data by cluster â†’ Returns cluster-specific time series | Chart shows Prod-Cluster-A only:<br>On-demand: $8,000<br>Spot: $3,000<br>Savings: $5,000 (62.5%) |
| Compare multiple clusters | Legend shows different colored lines per cluster | Queries data for selected clusters | Multi-line chart with cluster comparison |

---

## 10. Client Dashboard - Clusters Management

### Scenario Table: Viewing Cluster Details

| User Action | What User Sees (Frontend) | What Happens (Backend) | Display |
|-------------|---------------------------|------------------------|---------|
| Navigate to Clusters tab | List of clusters with summary info | GET `/api/client/{id}/clusters` â†’ Returns clusters with instance counts, health status | Clusters list:<br>Prod-Cluster-A (45 instances)<br>Prod-Cluster-B (32 instances)<br>Dev-Cluster (12 instances) |
| Click on "Prod-Cluster-A" | Panel expands showing instance list | GET `/api/client/{id}/clusters/A/instances` â†’ Returns all instances in cluster with status, type, pool | Instance list table with columns: ID, Type, Status, Pool, Cost |
| Click on instance "i-123" | Modal popup opens with instance details | GET `/api/client/instances/i-123/switch-history` â†’ GET `/api/client/instances/i-123/available-options` â†’ Returns history + alternate pools | Popup shows detailed instance view |

### Scenario Table: Instance Detail Popup

| User Action | What User Sees (Frontend) | What Happens (Backend) | Visualization |
|-------------|---------------------------|------------------------|---------------|
| View switch history graph | Line graph showing instance switching history over 7 days | Switch history data rendered | Timeline showing: Started on-demand â†’ Switched to pool-A â†’ Switched to pool-B â†’ Current |
| View alternate pools section | Table with 5 rows showing: Pool name, Instance type, Price, Interruption freq | Queries pricing API for compatible pools â†’ Sorts by cost â†’ Returns top 5 alternatives<br>Data cached for 12 hours | Pool-123: m5.large, $0.045/hr, Low<br>Pool-456: m5.large, $0.042/hr, Medium<br>... |
| Pricing data updates | Timestamp shows "Updated 2hrs ago" | Cron job runs every 12h â†’ Fetches latest spot prices â†’ Updates pool pricing cache | Fresh pricing data |
| Click "Force On-Demand" button | Modal appears with duration selector | N/A (confirmation) | "How long? 1h / 6h / 12h / 24h / Custom" |
| Select 6 hours and confirm | Confirmation: "Force i-123 to on-demand for 6 hours?" | Shows warning modal | Duration selected |
| Click "Apply" | Loading indicator, then progress feedback | POST `/api/client/instances/i-123/force-on-demand` `{duration_hours: 6}` â†’ Creates temporary override â†’ Initiates switch to on-demand â†’ Sets auto-revert timer | Switch initiated |
| Watch instance switch | Popup shows: "Switching to on-demand..." â†’ "Complete" | Instance switched â†’ Override record created â†’ Timer scheduled for 6h later | Instance now on-demand |
| 6 hours later (auto-revert) | If popup still open, shows: "Reverting to ML management..." | Timer expires â†’ Removes override â†’ ML engine evaluates instance â†’ Suggests best pool â†’ Auto-switches | Instance returned to ML control |

### Scenario Table: Cluster-Level Force On-Demand

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| In Prod-Cluster-A view, click "Force Cluster to On-Demand" | Modal with duration selector appears | N/A (confirmation) | Cluster-wide control shown |
| Select 12 hours and confirm | Confirmation: "Force all 45 instances in Prod-Cluster-A to on-demand for 12 hours?" | Shows  warning | Cluster-level action confirmed |
| Click "Apply" | Progress modal: "Processing 0/45 instances..." | POST `/api/client/clusters/A/force-on-demand` `{duration_hours: 12}` â†’ For each instance in cluster: Creates override â†’ Switches to on-demand â†’ Progress updates sent via WebSocket | Batch switching started |
| Watch progress | Progress bar: 20% â†’ 50% â†’ 100% "45/45 complete" | Each instance switches â†’ Progress counter increments â†’ Updates pushed to frontend | All cluster instances on on-demand |

### Scenario Table: Client-Level Force On-Demand

| User Action | What User Sees (Frontend) | What Happens (Backend) | Result |
|-------------|---------------------------|------------------------|--------|
| In cluster list view, click "Force All Clusters to On-Demand" | Warning modal: "This will affect ALL clusters (89 total instances)" | N/A (confirmation) | Client-wide warning shown |
| Select 24 hours and confirm | Confirmation with impact summary | Shows full impact | Client understands scope |
| Click "Apply" | Progress by cluster: Prod-A (0/45), Prod-B (0/32), Dev (0/12) | POST `/api/client/{id}/force-on-demand-all` `{duration_hours: 24}` â†’ For each cluster â†’ For each instance â†’ Switch to on-demand | Client-wide migration started |
| Watch multi-cluster progress | All three progress bars update in parallel | Parallel processing per cluster â†’ Real-time WebSocket updates | All client instances on on-demand |

---

## 11. Client Dashboard - Unregistered Instances

### Scenario Table: Managing Unauthorized Instances

| User Action | What User Sees (Frontend) | What Happens (Backend) | Display |
|-------------|---------------------------|------------------------|---------|
| Navigate to Unregistered Instances | Table showing instances not in any cluster | GET `/api/governance/unauthorized` â†’ Queries instances where cluster_id IS NULL â†’ Returns instance details | Table with columns: Instance ID, Type, Region, Created, Status, Flag Action |
| View unregistered instance info | Row shows: i-unknown-789, t3.medium, us-east-1, 3 days ago, running | Data from query | Full instance metadata displayed |
| Click "Authorized" flag | Checkbox/flag turns green | N/A (client-side state) | Instance marked as authorized locally |
| Click "Unauthorized" flag on another | Flag turns red | N/A (client-side state) | Instance marked for termination |
| Click "Apply" button | Confirmation modal: "Terminate 3 unauthorized instances?" | Lists flagged instances for review | Confirmation required |
| Confirm termination | Progress modal appears: "Terminating instances..." | POST `/api/governance/instances/apply` â†’ For each unauthorized flagged instance:<br>1. Sends termination command<br>2. Waits for confirmation<br>3. Updates database: `status='terminated', deleted_at=NOW()`<br>4. Updates progress | Termination in progress |
| Watch progress bar | "Terminating 1/3... â†’ 3/3 Complete" | Each instance terminated â†’ Progress updated | All unauthorized instances terminated |
| List refreshes | Terminated instances removed, authorized ones moved to clusters if applicable | GET `/api/governance/unauthorized` called again â†’ Returns updated list | Clean list of remaining unregistered instances |

---

## 12. Client Dashboard - Volumes Management

### Scenario Table: Cleaning Up Orphaned Volumes

| User Action | What User Sees (Frontend) | What Happens (Backend) | Display |
|-------------|---------------------------|------------------------|---------|
| Navigate to Volumes tab | Table of unattached/orphaned volumes | GET `/api/storage/unmapped-volumes` â†’ Queries volumes WHERE instance_id IS NULL AND last_attached < 30 days ago â†’ Returns volume details | Vol-001 (100GB, GP3, $10/mo, unattached 45 days)<br>Vol-002 (50GB, GP2, $5/mo, unattached 12 days) |
| Review volume information | Each row shows: Volume ID, Size, Type, Cost/month, Last attached date | Data from storage query | Full volume metadata |
| Flag Vol-001 as "Unsafe" | Red flag icon appears | N/A (client-side) | Marked for deletion |
| Flag Vol-002 as "Safe" | Green check icon appears | N/A (client-side) | Marked as keep |
| Click "Apply" button | Confirmation: "Delete 1 unsafe volume? This cannot be undone." | Shows deletion warning | Confirmation required |
| Confirm deletion | Progress: "Deleting volumes..." | POST `/api/storage/volumes/cleanup` â†’ For each unsafe volume:<br>1. Creates snapshot backup<br>2. Sends delete command to cloud<br>3. Waits for confirmation<br>4. Updates DB: `status='deleted'`<br>5. Logs cost savings | Deletion in progress |
| Deletion completes | Success: "1 volume deleted. Saving $10/month" | Volume removed from cloud and database | Cost savings reported |

---

## 13. Client Dashboard - Snapshots Management

### Scenario Table: Removing Unused Snapshots

| User Action | What User Sees (Frontend) | What Happens (Backend) | Display |
|-------------|---------------------------|------------------------|---------|
| Navigate to Snapshots tab | Table of unused AMI snapshots | GET `/api/storage/ami-snapshots` â†’ Queries snapshots WHERE (associated_ami IS NULL OR ami_deleted=true) AND created_at < 90 days ago | Snap-001 (AMI deleted, 120 days old, 50GB, $2.5/mo)<br>Snap-002 (Orphaned, 95 days old, 80GB, $4/mo) |
| Review snapshot details | Rows show: Snapshot ID, Size, Age, Status, Monthly cost | Data from snapshot query | Snapshot metadata displayed |
| Flag Snap-001 for deletion | Checkbox selected | N/A (client-side) | Marked for deletion |
| Flag Snap-002 for deletion | Checkbox selected | N/A (client-side) | Marked for deletion |
| Click "Apply" | Confirmation: "Delete 2 snapshots? Total savings: $6.5/month" | Shows savings calculation | Confirmation with cost impact |
| Confirm deletion | Progress indicator | POST `/api/storage/snapshots/cleanup` â†’ For each snapshot:<br>1. Verifies not in use<br>2. Sends delete command<br>3. Updates database<br>4. Calculates savings | Snapshot cleanup in progress |
| Success notification | "2 snapshots deleted. Saving $6.50/month" | Snapshots removed, cost tracking updated | Monthly cost reduced |

---

## Summary: Data Flow Pattern

### General Request Flow

```
Frontend User Action
    â†“
Frontend JavaScript Event Handler
    â†“
API Request (GET/POST/PUT/DELETE /api/...)
    â†“
Backend API Server (FastAPI/Express)
    â†“
Authentication & Authorization Check
    â†“
Business Logic Layer
    â†“
Database Query / External API Call / ML Model
    â†“
Response Processing
    â†“
JSON Response to Frontend
    â†“
State Update (React useState/Context)
    â†“
UI Re-render
    â†“
User Sees Updated State
```

### Real-Time Data Flow (WebSocket)

```
Backend Event Occurs (switch, state change, etc.)
    â†“
Event Published to Message Queue
    â†“
WebSocket Server Picks Up Event
    â†“
WebSocket Broadcasts to Subscribed Clients
    â†“
Frontend WebSocket Handler Receives Event
    â†“
State Updated (no API call needed)
    â†“
UI Re-renders with Live Data
```

---

## Key Patterns

### Pattern 1: List â†’ Detail â†’ Action
- User views list (GET /api/resource)
- Clicks item â†’ Detail view (GET /api/resource/{id})
- Performs action â†’ API call (POST/PUT/DELETE)
- List refreshes automatically

### Pattern 2: Confirmation â†’ Progress â†’ Refresh
- User clicks destructive action
- Confirmation modal appears
- User confirms â†’ API call with progress updates
- Progress bar shows real-time status
- Completion â†’ Auto-refresh of affected data

### Pattern 3: Real-Time Monitoring
- Component mounts â†’ Initial data fetch
- Auto-refresh timer starts (30s interval)
- WebSocket connection established for live events
- Data updates from both polling AND WebSocket
- Component unmounts â†’ Cleanup timers and connections

### Pattern 4: Flag â†’ Batch Apply
- User reviews list of items
- Flags items with different states
- Clicks "Apply" â†’ Batch operation
- Backend processes all flagged items
- Progress feedback for batch operation
- List refreshes with results

---

# PART 2: PRODUCTION-GRADE IMPROVEMENTS

## Overview: Transition to Enterprise-Grade ML & Decision Engine

This section outlines the required architectural upgrades to transform the current system from a functional prototype to a production-ready, enterprise-grade platform.

---

## Phase 1: Event-Driven Architecture (Speed Upgrade)

### Current State vs. Required State

| Aspect | Current State | Enterprise Requirement | Impact |
|--------|--------------|----------------------|--------|
| **Trigger Mechanism** | Scheduled polling (scheduler.py runs every 5 minutes) | Event-driven real-time reactions | Pod at 12:01 waits until 12:05 â†’ Sub-second response needed |
| **Detection Latency** | Up to 5 minutes | < 1 second | Critical for production workloads |
| **API Calls** | Periodic "Do I need nodes?" queries | Kubernetes API stream watching | Reduced API overhead, instant awareness |
| **Scaling Speed** | Batch processing every cycle | Immediate per-event processing | Faster application responsiveness |

### Implementation Details

#### New Component: Kubernetes Event Watcher

**File**: `backend/watchers/k8s_event_stream.py`

**Purpose**: Replace polling with real-time Kubernetes API event streaming

**Code Structure**:
```python
from kubernetes import client, watch
import redis

def watch_pending_pods():
    """
    Real-time stream watcher for Kubernetes pod events.
    Triggers optimization immediately when pods enter Pending state.
    """
    v1 = client.CoreV1Api()
    w = watch.Watch()
    redis_client = redis.Redis(host='localhost', port=6379)
    
    # Real-time stream, no polling
    for event in w.stream(v1.list_pod_for_all_namespaces):
        pod = event['object']
        
        # Trigger Optimizer immediately on Pending pods
        if event['type'] == 'ADDED' and pod.status.phase == 'Pending':
            print(f"ğŸš¨ Pod {pod.metadata.name} is Pending! Triggering Instant Scale-Up...")
            
            # Push to Redis Queue for immediate execution
            optimization_request = {
                'pod_uid': pod.metadata.uid,
                'pod_name': pod.metadata.name,
                'namespace': pod.metadata.namespace,
                'resource_requests': pod.spec.containers[0].resources.requests,
                'timestamp': event['object'].metadata.creation_timestamp
            }
            redis_client.lpush('optimization_queue', json.dumps(optimization_request))
```

### Scenario Table: Event-Driven Optimization Flow

| Event | Current System (Polling) | New System (Event-Driven) | Time Saved |
|-------|-------------------------|--------------------------|------------|
| New pod created in Pending state | Waits for next scheduler cycle (0-5 mins) | Watcher detects immediately â†’ Triggers optimizer | Up to 5 minutes |
| Optimizer evaluates spot pools | Runs in batch with other pending pods | Processes this pod immediately via Redis queue | Instant processing |
| Node provisioning | Delayed by detection latency | Starts immediately after pool selection | 5 minutes faster |
| Pod scheduled to node | Total time: 5-10 minutes | Total time: < 1 minute | 80-90% reduction |

### Backend Changes Required

| Component | Change Type | Description |
|-----------|------------|-------------|
| `scheduler.py` | Deprecate | Remove 5-minute cron job, replace with event listener |
| `watchers/k8s_event_stream.py` | **NEW** | Kubernetes API watcher for pod events |
| `workers/optimizer_worker.py` | **NEW** | Redis queue consumer for optimization tasks |
| `config/redis.yaml` | **NEW** | Redis configuration for task queue |
| `requirements.txt` | Update | Add `kubernetes>=28.0.0`, `redis>=5.0.0` |

---

## Phase 2: Application Performance Metrics (ML Upgrade)

### Current State vs. Required State

| Aspect | Current State | Enterprise Requirement | Benefit |
|--------|--------------|----------------------|---------|
| **Optimization Criteria** | Instance stability (Family Stress, interruption history) | Application performance (latency, throughput, error rate) | Optimize for business metrics, not just uptime |
| **Data Source** | AWS Spot Advisor, historical interruption data | Prometheus/Datadog application metrics | Real-time app health awareness |
| **Decision Logic** | "Is this spot instance safe?" | "Can this spot instance handle 500 req/s with <200ms latency?" | Performance-aware scaling |
| **ML Model Input** | Spot pricing, interruption frequency | Pricing + CPU usage + memory + latency + throughput | Holistic optimization |

### Implementation Details

#### New Pipeline: Metric Ingestion

**File**: `backend/pipelines/metric_ingestor.py`

**Purpose**: Ingest and process application performance metrics from monitoring systems

**Data Flow**:
```
Prometheus/Datadog
    â†“
Metric Ingestor (pulls every 30s)
    â†“
Metrics Database (TimescaleDB)
    â†“
ML Scoring Engine
    â†“
Enhanced Optimization Decision
```

**Key Metrics to Ingest**:

| Metric Category | Prometheus Query | Purpose | Threshold Example |
|----------------|------------------|---------|-------------------|
| **Request Latency** | `histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))` | Ensure instance can handle load | P95 < 200ms |
| **Throughput** | `rate(http_requests_total[5m])` | Track requests per second | > 100 req/s sustained |
| **Error Rate** | `rate(http_requests_total{status=~"5.."}[5m])` | Detect degraded instances | < 1% errors |
| **CPU Utilization** | `rate(container_cpu_usage_seconds_total[5m])` | Identify rightsizing opportunities | 60-80% optimal |
| **Memory Pressure** | `container_memory_working_set_bytes / container_spec_memory_limit_bytes` | Prevent OOM kills | < 85% |

### Scenario Table: Performance-Based Optimization

| Scenario | Current Decision | New ML-Enhanced Decision | Outcome |
|----------|-----------------|-------------------------|---------|
| Pod on t3.medium, latency spiking to 400ms | Check spot interruption risk â†’ Stay if safe | Check latency metric â†’ Interruption risk â†’ Recommend c5.large (better CPU) | Better user experience |
| Low-traffic app on c5.xlarge | Optimize for cost â†’ Switch to cheaper t3.large | Analyze actual CPU usage (15%) â†’ Recommend t3.small | 75% cost savings |
| Database pod with memory-intensive workload | Generic optimization | Detect high memory usage â†’ Prioritize memory-optimized instances (r5 family) | Prevent crashes |
| Batch processing job | Time-based optimization | Analyze completion time metrics â†’ Select compute-optimized pools | Faster job completion |

### Code Changes Required

| File | Change Type | Description |
|------|------------|-------------|
| `pipelines/metric_ingestor.py` | **NEW** | Prometheus/Datadog integration, metric pulling |
| `ml_models/scoring.py` | Update | Add `performance_score` parameter to model input |
| `logic/decision_engine.py` | Update | Incorporate performance metrics into decision matrix |
| `database/schema.sql` | Update | Add `instance_metrics` table for time-series data |
| `requirements.txt` | Update | Add `prometheus-api-client>=0.5.0`, `datadog-api-client>=2.0.0` |

**Updated ML Model Formula**:
```
Old: final_score = (cost_weight * cost_score) + (stability_weight * stability_score)

New: final_score = (
    cost_weight * cost_score +
    stability_weight * stability_score +
    performance_weight * performance_score +
    capacity_weight * capacity_score
)

Where:
- performance_score = f(latency, throughput, error_rate)
- capacity_score = f(cpu_available, memory_available)
```

---

## Phase 3: Nuclear-Proof Safety Guardrails

### Current State vs. Required State

| Safety Aspect | Current State | Enterprise Requirement | Risk Mitigation |
|---------------|--------------|----------------------|-----------------|
| **Disruption Control** | Basic logic: `if interruptions > 3: switch` | Pod Disruption Budget (PDB) awareness | Prevent violating Kubernetes cluster policies |
| **Resource Allocation** | Custom bin-packer with heuristics | Google OR-Tools constraint solver (Linear Programming) | Mathematically proven optimal packing |
| **Drain Safety** | Drain nodes without app-level checks | Check PDB before draining any node | Zero-downtime guarantee |
| **Failure Handling** | Retry logic, basic fallbacks | Complex constraint solving with multiple fallback paths | Enterprise-grade reliability |

### Implementation Details

#### Update 1: Pod Disruption Budget Awareness

**Purpose**: Respect Kubernetes PDB policies to prevent accidental service disruptions

**Scenario Table: PDB-Aware Draining**

| Action | Without PDB Check | With PDB Check | Outcome |
|--------|------------------|----------------|---------|
| Optimizer wants to drain node-A | Immediately cordons and drains node | Checks PDB: `kubectl get pdb` â†’ `allowed_disruptions: 0` â†’ **ABORT** | Prevents service outage |
| Node has 3 replicas of critical app | All 3 pods evicted simultaneously | PDB requires min 2 replicas running â†’ Drains pods one-by-one | Maintains availability |
| Cluster-wide optimization | Could drain 50% of nodes at once | PDB limits: Only drain nodes that don't violate any PDB | Safe, gradual migration |

**Code Implementation**:
```python
# File: backend/logic/safe_drain.py

from kubernetes import client

def can_drain_node(node_name):
    """
    Check if draining this node violates any Pod Disruption Budget.
    Returns: (can_drain: bool, reason: str)
    """
    v1 = client.CoreV1Api()
    policy_v1 = client.PolicyV1Api()
    
    # Get all pods on this node
    pods = v1.list_pod_for_all_namespaces(
        field_selector=f"spec.nodeName={node_name}"
    ).items
    
    for pod in pods:
        # Find PDB for this pod
        pdbs = policy_v1.list_namespaced_pod_disruption_budget(
            namespace=pod.metadata.namespace
        ).items
        
        for pdb in pdbs:
            if matches_pdb(pod, pdb):
                if pdb.status.disruptions_allowed < 1:
                    return False, f"PDB {pdb.metadata.name} has 0 disruptions allowed"
    
    return True, "Safe to drain"
```

#### Update 2: Constraint Solver with Google OR-Tools

**Purpose**: Replace heuristic bin-packing with mathematically proven optimal solutions

**Comparison Table**:

| Aspect | Current Custom Bin-Packer | Google OR-Tools | Advantage |
|--------|--------------------------|-----------------|-----------|
| **Algorithm** | First-fit decreasing heuristic | Linear Programming (LP solver) | Guaranteed optimal solution |
| **Constraints** | Simple: memory + CPU | Complex: Memory + CPU + Affinity + Taints + PDB + Cost | Handles real-world complexity |
| **Proof** | Best-effort, may not be optimal | Mathematically proven optimal | Enterprise confidence |
| **Performance** | Fast but approximate | Slightly slower but exact | Acceptable trade-off for correctness |

**Code Implementation**:
```python
# File: backend/logic/constraint_solver.py

from ortools.linear_solver import pywraplp

def optimize_pod_placement(pods, nodes):
    """
    Use Google OR-Tools to find optimal pod-to-node assignment.
    
    Constraints:
    - CPU capacity per node
    - Memory capacity per node
    - Pod anti-affinity rules
    - Cost minimization
    """
    solver = pywraplp.Solver.CreateSolver('SCIP')
    
    # Decision variables: x[pod][node] = 1 if pod assigned to node
    x = {}
    for pod in pods:
        for node in nodes:
            x[(pod.id, node.id)] = solver.IntVar(0, 1, f"x_{pod.id}_{node.id}")
    
    # Constraint 1: Each pod must be assigned to exactly one node
    for pod in pods:
        solver.Add(sum(x[(pod.id, node.id)] for node in nodes) == 1)
    
    # Constraint 2: Node CPU capacity
    for node in nodes:
        solver.Add(
            sum(pod.cpu_request * x[(pod.id, node.id)] for pod in pods)
            <= node.cpu_capacity
        )
    
    # Constraint 3: Node memory capacity
    for node in nodes:
        solver.Add(
            sum(pod.memory_request * x[(pod.id, node.id)] for pod in pods)
            <= node.memory_capacity
        )
    
    # Objective: Minimize total cost
    solver.Minimize(
        sum(node.cost * x[(pod.id, node.id)] 
            for pod in pods for node in nodes)
    )
    
    # Solve
    status = solver.Solve()
    
    if status == pywraplp.Solver.OPTIMAL:
        return extract_solution(x, pods, nodes)
    else:
        raise Exception("No optimal solution found")
```

### Dependencies Required

| Package | Version | Purpose |
|---------|---------|---------|
| `ortools` | 9.6.2534 | Constraint solving |
| `kubernetes` | >= 28.0.0 | PDB API access |

---

## Phase 4: Hybrid Agent Architecture

### Current State vs. Required State

| Aspect | Current (Agentless) | Required (Hybrid) | Reason for Change |
|--------|---------------------|-------------------|-------------------|
| **Metrics Source** | AWS CloudWatch API | CloudWatch + In-cluster DaemonSet | CloudWatch has 5-min delay, misses container-level RAM |
| **RAM Visibility** | EC2 instance-level only | Container-level accurate metrics | Critical for rightsizing decisions |
| **Disk I/O** | Limited/delayed | Real-time per-pod metrics | Optimize for I/O-heavy workloads |
| **Network Performance** | Approximate from CloudWatch | Actual pod-to-pod latency | Network-sensitive app optimization |
| **Security Model** | API-only (secure but limited) | Reverse tunnel (agent pulls commands) | Agent never accepts incoming connections |

### Implementation Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Control Plane (HQ)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Metric Aggregator (receives agent data)         â”‚   â”‚
â”‚  â”‚  Command Queue (agent pulls for instructions)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–²
                          â”‚ HTTPS (agent-initiated, reverse tunnel)
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Kubernetes Cluster                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DaemonSet: atharva-agent (one pod per node)     â”‚   â”‚
â”‚  â”‚  - Collects: RAM, Disk, Network per container    â”‚   â”‚
â”‚  â”‚  - Sends metrics to HQ every 30s                 â”‚   â”‚
â”‚  â”‚  - Polls for commands (never accepts inbound)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scenario Table: Hybrid vs. Agentless Comparison

| Use Case | Agentless (Current) | Hybrid (New) | Improvement |
|----------|---------------------|--------------|-------------|
| **RAM Usage Detection** | CloudWatch: 5-min delay, instance-level | Agent: 30-sec update, container-level | 10x faster, accurate per-pod |
| **Memory Spike Response** | Pod OOM killed before system reacts | Detected in 30s â†’ Pre-emptive scale-up | Prevents crashes |
| **Disk I/O Optimization** | No visibility into container disk usage | Agent reports per-pod disk I/O | Can recommend EBS-optimized instances |
| **Onboarding Complexity** | Zero-touch (API keys only) | Requires DaemonSet installation | Trade-off: Better data vs. setup complexity |
| **Security Surface** | Minimal (API only) | Agent pulls commands (no inbound ports) | Still secure via reverse tunnel |

### Agent Implementation

**File**: `agents/daemonset/metric_collector.py`

**Purpose**: Lightweight agent running on each node to collect container-level metrics

**Code Structure**:
```python
import psutil
import docker
import requests
import time

class MetricCollector:
    def __init__(self, hq_url, cluster_id, api_token):
        self.hq_url = hq_url
        self.cluster_id = cluster_id
        self.api_token = api_token
        self.docker_client = docker.from_env()
    
    def collect_container_metrics(self):
        """Collect RAM, Disk, Network for all containers on this node."""
        metrics = []
        
        for container in self.docker_client.containers.list():
            stats = container.stats(stream=False)
            
            metrics.append({
                'container_id': container.id,
                'container_name': container.name,
                'pod_name': container.labels.get('io.kubernetes.pod.name'),
                'namespace': container.labels.get('io.kubernetes.pod.namespace'),
                'memory_usage_bytes': stats['memory_stats']['usage'],
                'memory_limit_bytes': stats['memory_stats']['limit'],
                'cpu_usage_percent': self.calculate_cpu_percent(stats),
                'disk_read_bytes': stats['blkio_stats']['io_service_bytes_recursive'][0]['value'],
                'disk_write_bytes': stats['blkio_stats']['io_service_bytes_recursive'][1]['value'],
                'network_rx_bytes': stats['networks']['eth0']['rx_bytes'],
                'network_tx_bytes': stats['networks']['eth0']['tx_bytes'],
                'timestamp': time.time()
            })
        
        return metrics
    
    def send_metrics_to_hq(self, metrics):
        """Send collected metrics to control plane via HTTPS (reverse tunnel)."""
        response = requests.post(
            f"{self.hq_url}/api/agent/metrics",
            json={
                'cluster_id': self.cluster_id,
                'node_name': self.get_node_name(),
                'metrics': metrics
            },
            headers={'Authorization': f'Bearer {self.api_token}'}
        )
        return response.status_code == 200
    
    def poll_for_commands(self):
        """Check if HQ has any commands (agent pulls, never accepts)."""
        response = requests.get(
            f"{self.hq_url}/api/agent/commands",
            headers={'Authorization': f'Bearer {self.api_token}'},
            params={'node_name': self.get_node_name()}
        )
        
        if response.status_code == 200 and response.json().get('commands'):
            return response.json()['commands']
        return []
    
    def run(self):
        """Main loop: collect metrics every 30s, send to HQ."""
        while True:
            try:
                # Collect and send metrics
                metrics = self.collect_container_metrics()
                self.send_metrics_to_hq(metrics)
                
                # Poll for commands (e.g., "drain this node")
                commands = self.poll_for_commands()
                for command in commands:
                    self.execute_command(command)
                
                time.sleep(30)
            except Exception as e:
                print(f"Error in metric collection: {e}")
                time.sleep(30)
```

**DaemonSet Deployment**:
```yaml
# File: k8s/daemonset-agent.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: atharva-metric-agent
  namespace: atharva-system
spec:
  selector:
    matchLabels:
      app: atharva-agent
  template:
    metadata:
      labels:
        app: atharva-agent
    spec:
      hostNetwork: true  # Access host-level metrics
      containers:
      - name: metric-collector
        image: atharva/metric-agent:latest
        env:
        - name: HQ_URL
          value: "https://hq.atharva.ai"
        - name: CLUSTER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.uid
        - name: API_TOKEN
          valueFrom:
            secretKeyRef:
              name: atharva-agent-secret
              key: token
        volumeMounts:
        - name: docker-sock
          mountPath: /var/run/docker.sock
          readOnly: true
      volumes:
      - name: docker-sock
        hostPath:
          path: /var/run/docker.sock
```

### Security Model: Reverse Tunnel

**Key Principle**: Agent NEVER accepts incoming connections. It ONLY initiates outbound HTTPS to HQ.

| Security Aspect | Implementation | Benefit |
|----------------|----------------|---------|
| **Authentication** | JWT token issued by HQ during onboarding | Agent proves identity to HQ |
| **Command Flow** | Agent polls HQ for commands (not pushed to agent) | No open ports on agent, firewall-friendly |
| **TLS Encryption** | All communication over HTTPS | Data in transit protected |
| **Minimal Privileges** | Agent runs as non-root, read-only Docker socket access | Limited blast radius if compromised |

---

## Summary: Migration Roadmap

### Implementation Priority

| Phase | Priority | Estimated Effort | Impact | Dependencies |
|-------|----------|-----------------|--------|--------------|
| **Phase 1: Event-Driven** | **HIGH** | 2-3 weeks | Immediate latency reduction (5min â†’ <1sec) | Redis, Kubernetes client library |
| **Phase 2: Performance Metrics** | **MEDIUM** | 3-4 weeks | Better optimization decisions, fewer errors | Prometheus/Datadog integration |
| **Phase 3: Safety Guardrails** | **HIGH** | 2 weeks | Zero-downtime guarantee, enterprise trust | OR-Tools library |
| **Phase 4: Hybrid Agents** | **LOW** | 4-5 weeks | Better visibility, optional for MVP | Docker API access, DaemonSet deployment |

### Success Metrics

| Metric | Current | Target (Post-Upgrade) |
|--------|---------|----------------------|
| **Pod Scheduling Latency** | 5-10 minutes | < 30 seconds |
| **Optimization Accuracy** | 85% (cost-only) | 95% (cost + performance) |
| **Service Disruptions** | ~2 per month | 0 (PDB-aware) |
| **Metric Freshness** | 5 minutes | 30 seconds (with agents) |
| **ML Model Confidence** | 80% | 95% (with app metrics) |

### Testing Strategy Before Production

1. **Canary Deployment**: Test Phase 1 on 10% of clusters for 1 week
2. **A/B Testing**: Compare old vs new optimization logic on parallel clusters
3. **Chaos Engineering**: Simulate node failures, verify PDB compliance
4. **Load Testing**: Ensure metric ingestion scales to 10,000 pods
5. **Security Audit**: Penetration testing of agent â†’ HQ communication